universe = vanilla
executable = download_subject.sh
arguments = $(subject)
opath = /home/groups/abcd_data/ABCD-Missingness/ABCC_download/output
log    = $(opath)/$(Cluster).$(Process)_download_$(subject).log
output = $(opath)/$(Cluster).$(Process)_download_$(subject).out
error  = $(opath)/$(Cluster).$(Process)_download_$(subject).err

# Specify that HTCondor should transfer files to and from the
#  computer where each job runs. The last of these lines *would* be
#  used if there were any other files needed for the executable to use.
should_transfer_files = YES
when_to_transfer_output = ON_EXIT

# input is defined separately so we can try to get data flow working later.
input = /home/groups/abcd_data/dwnld_preproc/download/AllBaselineImages_FMRIRESULTS.csv
# We also need these files, but don't consider them for data flow.
transfer_input_files = http://proxy.chtc.wisc.edu/SQUID/chtc/el8/python310.tar.gz, /home/groups/abcd_data/dwnld_preproc/download/pyPackages.tar.gz, download_subject.py, credfile, download_subject.sh, filtered_problem_manifest.txt

transfer_output_files = ""

# Tell HTCondor what amount of compute resources
#  each job will need on the computer where it runs.
request_cpus = 4
request_memory = 3GB
request_disk = 15GB
Requirements = (Target.HasCHTCProjects == true)
priority=5

max_materialize=100

#notify
notify_user=peverill@wisc.edu

# Tell HTCondor to iterate over the subject file
#queue subject from ../../dwnld_preproc/ALL_SUBJECTS_11873.txt
#queue subject from remedialsubjects